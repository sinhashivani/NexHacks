---
description: "NexHacks â€“ Polymarket Correlation & Trending Tool"
require: ["**/*.py", "**/*.ts", "**/*.tsx", "database/**", "docs/**"]
---

# NexHacks â€“ Polymarket Correlation & Trending Tool

## High-level goal

Build a backend + simple frontend that helps Polymarket users:

- See **trending / most popular markets right now** (on Polymarket and, optionally, other platforms).
- Discover **correlated trades** and **parlay opportunities**.
- Discover **inverse / hedge trades**.
- Avoid **contradictory trades** in the UI.

We **do not** modify Polymarket itself. This is a separate app that reads data from:

- **Polymarket Gamma API** for markets & metadata.
- Optionally other prediction-market aggregators for crossâ€‘platform trends.
- Supabase (PostgreSQL) as our own data and analytics store.

Tech stack:

- Backend: **Python** (FastAPI - already set up in `api.py`).
- DB: **Supabase PostgreSQL** (connection via `database/supabase_connection.py`).
- Frontend: Lightweight web app (React/Next or simple SPA) â€“ not over-engineered.
- Optional AI: Gemini / embeddings for text similarity; Supabase `pgvector` if embeddings are stored.

---

## Existing database & project layout

We already have:

- Supabase project set up and connected from Python.
- CSV import completed for ~5,770 Polymarket markets in `markets` table.
- FastAPI app already running in `api.py`.
- Basic project tree:

```
NexHacks/
â”œâ”€â”€ api.py                          # FastAPI app (EXTEND THIS)
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ supabase_connection.py      # DB connection handler
â”‚   â”œâ”€â”€ schema.sql                  # Database schema
â”‚   â””â”€â”€ migrations/
â”‚       â”œâ”€â”€ 001_import_markets_from_csv_simple.py
â”‚       â””â”€â”€ 002_drop_unused_tables.sql
â”œâ”€â”€ polymarket/
â”‚   â”œâ”€â”€ get_markets_data.py         # Polymarket API integration
â”‚   â””â”€â”€ get_event_data.py           # Event fetching
â”œâ”€â”€ data/
â”‚   â””â”€â”€ polymarket_events_by_tags.csv  # Market data CSV
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ PROJECT_OVERVIEW.md
â”‚   â”œâ”€â”€ SUPABASE_SETUP.md
â””â”€â”€ .env                            # Environment variables
```

### Current tables

**markets:**
- `market_id` (text, unique)
- `market_slug`
- `question`
- `tag_label`
- `tag_id`
- `clob_token_ids`
- `active` (bool)
- `closed` (bool)

**parlay_suggestions:**
- `user_id`
- `base_market_id`
- `suggested_markets` (JSONB)
- `expected_return`
- `risk_level`
- `confidence`

**Removed (for now):** `user_trades`, `trade_correlations`, `related_trades`, `hedge_opportunities`. Those are computed onâ€‘theâ€‘fly instead of stored.

---

## Implementation priorities

### 1. Trending / "top trades right now" pipeline (CURRENT FOCUS)

**Goal:** A simple service that ranks markets by popularity and exposes them via REST endpoints, with optional category filters.

**Popularity inputs:**
- Polymarket Gamma markets for active markets and metadata.
- Liquidity / open interest / volume (either via Polymarket data APIs or approximated from price history and volumes).

**Tasks:**
- Add schema support for live metrics (create `market_metrics` table).
- Add a Python ingestion job that periodically fetches active markets from Polymarket API.
- Define a trending score in Python (simple weighted formula).
- REST endpoints in `api.py`: `GET /markets/trending?category={category}&limit={n}`

### 2. Category filtering

- Create `category_mapping` table to map tags to canonical categories.
- Add `canonical_category` to markets.
- Filter endpoints by category.

### 3. Correlation & similarity layer

- Text similarity (TF-IDF or embeddings).
- Price correlation (when price data available).
- Endpoints: `/markets/{id}/related`, `/markets/{id}/correlated`, `/markets/{id}/hedge-opportunities`

### 4. Parlay suggestion engine

- Use existing `parlay_suggestions` table.
- Implement parlay calculation logic.
- Endpoint: `/markets/{id}/parlay-suggestions`

### 5. Frontend

- Trending markets table.
- Market detail view with tabs.
- Contradiction prevention UI.

---

## Code organization

- **Extend `api.py`** - Add new endpoints here (don't create new FastAPI apps).
- **Use `database/supabase_connection.py`** - For all DB access.
- **Use existing services** - Business logic is in `services/`:
  - `services/trending.py` - Trending score calculation âœ…
  - `services/polymarket_api.py` - Polymarket API wrapper âœ…
  - `services/correlation.py` - Correlation logic (TODO)
  - `services/parlay.py` - Parlay suggestions (TODO)

---

## Implementation guidelines

- Prefer FastAPI for the backend (already set up in `api.py`).
- Use existing `database/supabase_connection.py` for DB access.
- Keep correlation and similarity functions pure where possible for testability.
- When in doubt: Prioritize simple, understandable heuristics over heavy infra.
- Optimize for hackathon-ready: working E2E path > perfect modeling.
- Respect this file as the source of truth for what endpoints and tables to create.
- Keep code organized under clear domains (markets, trending, correlation, parlay).

---

## Polymarket API details

- **Gamma API**: `https://gamma-api.polymarket.com` (public, no auth needed)
- **CLOB API**: `https://clob.polymarket.com` (public, for prices/orderbook)
- Existing integration in `polymarket/get_markets_data.py`
- Use existing functions: `ui()`, `mid()` for market data and prices

---

## Environment variables

- `SUPABASE_URL` - Supabase project URL
- `SUPABASE_ANON_KEY` - Supabase anon key
- `POLYMARKET_API_KEY` - Optional, for rate limits (if available)

---

## Current status

âœ… Database setup complete
âœ… Markets data imported (~5,770 markets)
âœ… FastAPI app structure exists
âœ… Polymarket API integration exists
âœ… Trending markets - COMPLETE
âœ… Project structure organized
ğŸš§ Correlation algorithms - IN PROGRESS
â³ Frontend - TODO
